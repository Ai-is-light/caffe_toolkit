## ResNet
[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) <br>

### 摘要
越深层的网络往往越难以训练。本文提出一种残差学习框架，使得比先前网络深的多的网络也易于训练。我们将网络中的层改写为
在参照该层输入的情况下学习残差函数的形式，替换之前那种无参考学习的方式。我们通过大量实验证明这种残差网络易于优化，
并且预测准确率随着网络深度的增加而增大。在ImageNet数据集上使用了一个152层的残差网络，深度是VGG网络的8倍但复杂度却更低。
使用这种残差网络的集合在ImageNet测试集上达到3.57%的错误率，这个结果赢得了ILSVRC2015年分类任务的第一名。
另外我们在CIFAR-10数据集上对100层和1000层的残差网络进行了分析。<br>
模型表示的深度在许多视觉识别任务中是最重要的影响因素。完全得益于极深层的表示，我们在COCO物体检测数据集上得到了28%的性能提升。
深度残差网络是我们在参加ILSVRC2015和COCO2015竞赛时提交的解决方案的基础，在这两个竞赛中我们还赢得了ImageNet检测、ImageNet定位、
COCO检测以及COCO分割等任务的第一名。<br>

### Introduction
深度网络可以将低/中/高层特征与分类器结合起来成为一种端到端的多层形式，其中特征的“层”可以通过增加网络层数（深度）来丰富。
最近的研究也表明网络深度对于网络的性能提升至关重要。<br>
那么，**是不是随着网络中堆叠的层数增加可以很容易的训练得到一个性能更好的网络呢？**
